{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import SimpleDirectoryReader\n",
    "import logging\n",
    "import sys\n",
    "from llama_index import ServiceContext, LLMPredictor, OpenAIEmbedding, PromptHelper\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "\n",
    "# Import local library\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Autoreload local library\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.readers.file.base:> [SimpleDirectoryReader] Total files added: 1\n",
      "> [SimpleDirectoryReader] Total files added: 1\n",
      "Loaded 1 documents\n",
      "First document metadata: {'file_name': 'O6_1A_Umweltgerechte_und_biodiversitaetsfoerdernde_Bewirtschaftung_(UBB)_2023_04.pdf'}\n",
      "First document text: Informationsblatt ÖPUL 2023  \n",
      "Umweltgerechte und biodiversitätsfördernde \n",
      "Bewirtschaftung    Seite 1 von 38 www.eama.at  | www.ama.at   \n",
      "  \n",
      "ÖPUL 2023  \n",
      "Umweltgerechte und biodivers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from oepul_chat.custom_pdf_reader import CustomPDFReader\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "def load_markdown_docs(filepath):\n",
    "    \"\"\"Load markdown docs from a directory, excluding all other file types.\"\"\"\n",
    "    loader = SimpleDirectoryReader(\n",
    "        input_dir=filepath,\n",
    "        exclude=[\"*.rst\", \"*.ipynb\", \"*.py\", \"*.bat\", \"*.txt\", \"*.png\", \"*.jpg\",\n",
    "                 \"*.jpeg\", \"*.csv\", \"*.html\", \"*.js\", \"*.css\", \"*.md\", \"*.json\"],\n",
    "        file_extractor={\".pdf\": CustomPDFReader()},\n",
    "        recursive=True\n",
    "    )\n",
    "\n",
    "    return loader.load_data()\n",
    "\n",
    "# documents = load_markdown_docs(\"data/\")\n",
    "\n",
    "# for testing only one doc \n",
    "documents = load_markdown_docs(\"data/sub\")\n",
    "\n",
    "\n",
    "print(\"Loaded {} documents\".format(len(documents)))\n",
    "print(\"First document metadata: {}\".format(documents[0].metadata))\n",
    "print(\"First document text: {}\".format(documents[0].text[0:180]))\n",
    "\n",
    "# Save the first document text for later\n",
    "first_doc_text = documents[0].text\n",
    "with open(\"first_doc_text.txt\", \"w\") as f:\n",
    "    f.write(first_doc_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory ./data/pdfs does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vali/repos/tu_wien/oepul-chat/notebooks/02_rag_llama_index.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vali/repos/tu_wien/oepul-chat/notebooks/02_rag_llama_index.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load in pdfs as llama index documents\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vali/repos/tu_wien/oepul-chat/notebooks/02_rag_llama_index.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m documents \u001b[39m=\u001b[39m SimpleDirectoryReader(\u001b[39m\"\u001b[39;49m\u001b[39m./data/pdfs\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mload_data()\n",
      "File \u001b[0;32m~/anaconda3/envs/oepul-chat-m/lib/python3.9/site-packages/llama_index/readers/file/base.py:110\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[0;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39melif\u001b[39;00m input_dir:\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(input_dir):\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDirectory \u001b[39m\u001b[39m{\u001b[39;00minput_dir\u001b[39m}\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dir \u001b[39m=\u001b[39m Path(input_dir)\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexclude \u001b[39m=\u001b[39m exclude\n",
      "\u001b[0;31mValueError\u001b[0m: Directory ./data/pdfs does not exist."
     ]
    }
   ],
   "source": [
    "# Load in pdfs as llama index documents\n",
    "documents = SimpleDirectoryReader(\"./data/pdfs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 283 documents\n",
      "First document metadata: {'page_label': '1', 'file_name': 'O6_10_Erosionsschutz_Wein_Obst_Hopfen_2022_12.pdf'}\n",
      "First document text: Informationsblatt ÖPUL 2023  \n",
      "Erosionsschutz  Wein, Obst und Ho pfen Seite 1 von 6 www.eama.at  | www.ama.at   \n",
      "  \n",
      " \n",
      "ÖPUL 2023  \n",
      "Erosionsschutz  Wein, Obst  und Hopfen  \n",
      "STAND Deze\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded {} documents\".format(len(documents)))\n",
    "print(\"First document metadata: {}\".format(documents[0].metadata))\n",
    "print(\"First document text: {}\".format(documents[0].text[0:180]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now the documents are splitted by page, this is IMO suboptimal a hierachical split could be beneficial as these documents are always strutured simmilary.\n",
    "\n",
    "But for now we will accept this and go over to the next step which is splitting the documents into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='text-davinci-003', temperature=0, max_tokens=256)\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    text_splitter=TokenTextSplitter(chunk_size=1024, chunk_overlap=20)\n",
    ")\n",
    "\n",
    "prompt_helper = PromptHelper(\n",
    "    context_window=4096,\n",
    "    num_output=256,\n",
    "    chunk_overlap_ratio=0.1,\n",
    "    chunk_size_limit=None\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    node_parser=node_parser,\n",
    "    prompt_helper=prompt_helper\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine(service_context=service_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"Welche Maßnahme trägt zur Verringerung der Treibhausgasemission bei?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oepul-chat-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
